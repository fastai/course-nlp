{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peter Norvig's spell-checker http://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the files \n",
    "http://norvig.com/big.txt\n",
    "\n",
    "http://norvig.com/spell-testset1.txt\n",
    "\n",
    "http://norvig.com/spell-testset2.txt\n",
    "\n",
    "and save them in the directory containing this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(word_list): \n",
    "    \"The subset of `word_list` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in word_list if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_tests():\n",
    "    assert correction('speling') == 'spelling'              # insert\n",
    "    assert correction('korrectud') == 'corrected'           # replace 2\n",
    "    assert correction('bycycle') == 'bicycle'               # replace\n",
    "    assert correction('inconvient') == 'inconvenient'       # insert 2\n",
    "    assert correction('arrainged') == 'arranged'            # delete\n",
    "    assert correction('peotry') =='poetry'                  # transpose\n",
    "    assert correction('peotryy') =='poetry'                 # transpose + delete\n",
    "    assert correction('word') == 'word'                     # known\n",
    "    assert correction('quintessential') == 'quintessential' # unknown\n",
    "    assert words('This is a TEST.') == ['this', 'is', 'a', 'test']\n",
    "    assert Counter(words('This is a test. 123; A TEST this is.')) == (\n",
    "           Counter({'123': 1, 'a': 2, 'is': 2, 'test': 2, 'this': 2}))\n",
    "    #assert len(WORDS) == 32192\n",
    "    #assert sum(WORDS.values()) == 1115504\n",
    "    skip = True\n",
    "    if(not skip):\n",
    "        assert WORDS.most_common(10) == [\n",
    "         ('the', 79808),\n",
    "         ('of', 40024),\n",
    "         ('and', 38311),\n",
    "         ('to', 28765),\n",
    "         ('in', 22020),\n",
    "         ('a', 21124),\n",
    "         ('that', 12512),\n",
    "         ('he', 12401),\n",
    "         ('was', 11410),\n",
    "         ('it', 10681)]\n",
    "        assert WORDS['the'] == 79808\n",
    "        assert P('quintessential') == 0\n",
    "        assert 0.07 < P('the') < 0.08\n",
    "    return 'unit_tests pass'\n",
    "\n",
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    # start = time.clock()\n",
    "    start = time.process_time()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    # dt = time.clock() - start\n",
    "    dt = time.process_time() - start \n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))\n",
    "    \n",
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit_tests pass\n"
     ]
    }
   ],
   "source": [
    "print(unit_tests())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate spellchecker performance on Development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75% of 270 correct (6% unknown) at 44 words per second \n"
     ]
    }
   ],
   "source": [
    "spelltest(Testset(open('spell-testset1.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate spellchecker performance on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68% of 400 correct (11% unknown) at 39 words per second \n"
     ]
    }
   ],
   "source": [
    "spelltest(Testset(open('spell-testset2.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai_v1",
   "language": "python",
   "name": "fastai_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
